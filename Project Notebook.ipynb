{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through the implementation and analysis of the Insider Trading Machine Learning Project. It walks through using the created dataset. The code for (1) pulling Form 4 data from EDGAR and (2) creating the dataset is in form4_pull.py and create_dataset.py, respectively.\n",
    "\n",
    "To start we load the dataset into a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv(\"dataset_6_12_spy_alt_norm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we conduct some simple data preprocessing. While we gathered return data for 1 (RET1), 6 (RET6), and 12 (RET12) months, we are only using RET12 data in this demo since this data provided the best results. Thus, we drop missing datapoints for RET12 ('None': points for which data was not available, 'Fail': points for which data failed to download, and any NaN values). We also drop the COMPANY ticker and MONTH columns, and cleanup the market cap category data. We also renamed RET12 as RET.\n",
    "\n",
    "Finally, we define a function to separate the non-binary discrete variables into multiple binary variables using the get_dummies function. We use this function later on to split market sector data into 10 binary variables, and market cap data into 3 binary variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleanup dataset\n",
    "\n",
    "dataset = dataset[dataset.RET12 != 'None']\n",
    "dataset = dataset[dataset.RET12 != 'Fail']\n",
    "dataset.dropna(axis=0, inplace=True)\n",
    "dataset = dataset.drop(['COMPANY'], axis=1)\n",
    "dataset = dataset.drop(['MONTH'], axis=1)\n",
    "dataset = dataset.drop(['RET1'], axis=1)\n",
    "dataset = dataset.drop(['RET6'], axis=1)\n",
    "dataset.rename(index=str, columns={'RET12': 'RET'}, inplace=True)\n",
    "dataset['MKTCAP'].replace('.*Small.', 'small', inplace=True, regex=True)\n",
    "dataset['MKTCAP'].replace('.*Mid.', 'mid', inplace=True, regex=True)\n",
    "dataset['MKTCAP'].replace('.*Large.', 'large', inplace=True, regex=True)\n",
    "\n",
    "#Create binary variables for non-binary discrete variables\n",
    "def preprocess_features(X):\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "    for col, col_data in X.iteritems():\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "        output = output.join(col_data)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample of the dataset for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NBC1</th>\n",
       "      <th>NBC2</th>\n",
       "      <th>NBC3</th>\n",
       "      <th>NBC4</th>\n",
       "      <th>NBC5</th>\n",
       "      <th>NBC6</th>\n",
       "      <th>NBC7</th>\n",
       "      <th>NBC8</th>\n",
       "      <th>NBC9</th>\n",
       "      <th>NBC10</th>\n",
       "      <th>...</th>\n",
       "      <th>NBV6</th>\n",
       "      <th>NBV7</th>\n",
       "      <th>NBV8</th>\n",
       "      <th>NBV9</th>\n",
       "      <th>NBV10</th>\n",
       "      <th>NBV11</th>\n",
       "      <th>NBV12</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>MKTCAP</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.172941746714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.0150660419401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-7.44391884623e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.0846813940397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.200503849076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.165907802061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>0.053128</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.269385255117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>0.053128</td>\n",
       "      <td>0.057414</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.136214279481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>0.053128</td>\n",
       "      <td>0.057414</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.125907415704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>0.053128</td>\n",
       "      <td>0.057414</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>mid</td>\n",
       "      <td>-0.0150232631055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NBC1  NBC2  NBC3  NBC4  NBC5      NBC6      NBC7      NBC8      NBC9  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.000000  0.160714   \n",
       "7   0.0   0.0   0.0   0.0   0.0  0.000000  0.000000  0.160714  0.202381   \n",
       "8   0.0   0.0   0.0   0.0   0.0  0.000000  0.160714  0.202381 -0.071429   \n",
       "9   0.0   0.0   0.0   0.0   0.0  0.160714  0.202381 -0.071429 -0.017857   \n",
       "\n",
       "      NBC10         ...              NBV6      NBV7      NBV8      NBV9  \\\n",
       "0  0.000000         ...          0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000         ...          0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000         ...          0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000         ...          0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000         ...          0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.160714         ...          0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.202381         ...          0.000000  0.000000  0.000000  0.089069   \n",
       "7 -0.071429         ...          0.000000  0.000000  0.089069  0.005034   \n",
       "8 -0.017857         ...          0.000000  0.089069  0.005034  0.989108   \n",
       "9  0.065476         ...          0.089069  0.005034  0.989108  0.053128   \n",
       "\n",
       "      NBV10     NBV11     NBV12       SECTOR  MKTCAP                 RET  \n",
       "0  0.000000  0.000000  0.000000  Health Care     mid     -0.172941746714  \n",
       "1  0.000000  0.000000  0.000000  Health Care     mid    -0.0150660419401  \n",
       "2  0.000000  0.000000  0.000000  Health Care     mid  -7.44391884623e-05  \n",
       "3  0.000000  0.000000  0.089069  Health Care     mid    -0.0846813940397  \n",
       "4  0.000000  0.089069  0.005034  Health Care     mid     -0.200503849076  \n",
       "5  0.089069  0.005034  0.989108  Health Care     mid     -0.165907802061  \n",
       "6  0.005034  0.989108  0.053128  Health Care     mid     -0.269385255117  \n",
       "7  0.989108  0.053128  0.057414  Health Care     mid     -0.136214279481  \n",
       "8  0.053128  0.057414  0.003005  Health Care     mid     -0.125907415704  \n",
       "9  0.057414  0.003005  0.003005  Health Care     mid    -0.0150232631055  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates statistics on return, normalized net buy count, and normalized net buy volume across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min return: -0.935858888252\n",
      "Max return: 256.921787964\n",
      "Mean return: 0.037375337105\n",
      "Median return: 0.00476292075858\n",
      "Std Dev of return: 0.887738362548\n",
      "First quartile: -0.129435886468\n",
      "Third quartile: 0.153846798354\n",
      "First third: -0.0820028933886\n",
      "Second third: 0.0923269618164\n",
      "Min NBC: -1.0\n",
      "Max NBC: 1.0\n",
      "Mean NBC: 0.0161937410671\n",
      "Median NBC: 0.0\n",
      "Std NBC: 0.202602555863\n",
      "FQ NBC: -0.0113122171946\n",
      "TQ NBC: 0.0185185185185\n",
      "Min NBV: -1.0\n",
      "Max NBV: 1.0\n",
      "Mean NBV: 0.00188582097983\n",
      "Median NBV: 0.0\n",
      "Std NBV: 0.119143472668\n",
      "FQ NBV: -0.00116961416493\n",
      "TQ NBV: 0.0\n"
     ]
    }
   ],
   "source": [
    "ret_data = dataset['RET'].apply(pd.to_numeric, errors='coerce')\n",
    "min_return = np.min(ret_data)\n",
    "max_return = np.max(ret_data)\n",
    "mean_return = np.mean(ret_data)\n",
    "median_return = np.median(ret_data)\n",
    "std_return = np.std(ret_data)\n",
    "fq_return = np.percentile(ret_data,25)\n",
    "tq_return = np.percentile(ret_data,75)\n",
    "ft_return = np.percentile(ret_data,33)\n",
    "st_return = np.percentile(ret_data,66)\n",
    "print \"Min return: \" + str(min_return)\n",
    "print \"Max return: \" + str(max_return)\n",
    "print \"Mean return: \" + str(mean_return)\n",
    "print \"Median return: \" + str(median_return)\n",
    "print \"Std Dev of return: \" + str(std_return)\n",
    "print \"First quartile: \" + str(fq_return)\n",
    "print \"Third quartile: \" + str(tq_return)\n",
    "print \"First third: \" + str(ft_return)\n",
    "print \"Second third: \" + str(st_return)\n",
    "\n",
    "all_nbc = np.concatenate([dataset['NBC' + str(i)].apply(pd.to_numeric, errors='coerce') for i in range(1,13)])\n",
    "min_nbc = min(all_nbc)\n",
    "max_nbc = max(all_nbc)\n",
    "mean_nbc = np.mean(all_nbc)\n",
    "median_nbc = np.median(all_nbc)\n",
    "std_nbc = np.std(all_nbc)\n",
    "fq_nbc = np.percentile(all_nbc, 25)\n",
    "tq_nbc = np.percentile(all_nbc, 75)\n",
    "print \"Min NBC: \" + str(min_nbc)\n",
    "print \"Max NBC: \" + str(max_nbc)\n",
    "print \"Mean NBC: \" + str(mean_nbc)\n",
    "print \"Median NBC: \" + str(median_nbc)\n",
    "print \"Std NBC: \" + str(std_nbc)\n",
    "print \"FQ NBC: \" + str(fq_nbc)\n",
    "print \"TQ NBC: \" + str(tq_nbc)\n",
    "\n",
    "all_nbv = np.concatenate([dataset['NBV' + str(i)].apply(pd.to_numeric, errors='coerce') for i in range(1,13)])\n",
    "min_nbv = min(all_nbv)\n",
    "max_nbv = max(all_nbv)\n",
    "mean_nbv = np.mean(all_nbv)\n",
    "median_nbv = np.median(all_nbv)\n",
    "std_nbv = np.std(all_nbv)\n",
    "fq_nbv = np.percentile(all_nbv, 25)\n",
    "tq_nbv = np.percentile(all_nbv, 75)\n",
    "print \"Min NBV: \" + str(min_nbv)\n",
    "print \"Max NBV: \" + str(max_nbv)\n",
    "print \"Mean NBV: \" + str(mean_nbv)\n",
    "print \"Median NBV: \" + str(median_nbv)\n",
    "print \"Std NBV: \" + str(std_nbv)\n",
    "print \"FQ NBV: \" + str(fq_nbv)\n",
    "print \"TQ NBV: \" + str(tq_nbv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram of return data shows that the returns are roughly normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJlZaU4iZmZW2v8HUwjQRWXLjEIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bdf61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEPCAYAAAByRqLpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1134a2610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEPCAYAAAByRqLpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113497050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ret_data, bins=100, range=(-.8,.8))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Return')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(all_nbc, bins=100, range=(-1,1))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('NBC')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(all_nbv, bins=100, range=(-1,1))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('NBV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the statistics, we decide to divide the target set into three categories:\n",
    "'above' = returns on the 3rd third of the data (higher than 2/3 of returns)\n",
    "'middle' = returns on the 2nd third of the data (between 1/3 and 2/3 of returns).\n",
    "'below' = returns on the 1st third of the data (below 1/3 of returns). This is done because of the assumption that creating a meaningful regression is a too ambitious goal for this project.\n",
    "\n",
    "We then randomly shuffle and split the dataset into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamephase/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['NBC1', 'NBC2', 'NBC3', 'NBC4', 'NBC5', 'NBC6', 'NBC7', 'NBC8', 'NBC9', 'NBC10', 'NBC11', 'NBC12', 'NBV1', 'NBV2', 'NBV3', 'NBV4', 'NBV5', 'NBV6', 'NBV7', 'NBV8', 'NBV9', 'NBV10', 'NBV11', 'NBV12', 'SECTOR', 'MKTCAP']\n",
      "\n",
      "Target column: RETURN_CAT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#Divide target set into 3 classes, and create new RETURN_CAT column\n",
    "dataset.loc[(dataset.RET.astype(np.float64) > ft_return) & (dataset.RET.astype(np.float64) < st_return), 'RETURN_CAT'] = np.str('STABLE')\n",
    "dataset.loc[(dataset.RET.astype(np.float64) >= st_return), 'RETURN_CAT'] = np.str('UP')\n",
    "dataset.loc[(dataset.RET.astype(np.float64) <= ft_return), 'RETURN_CAT'] = np.str('DOWN')\n",
    "\n",
    "#Separate dataset into feature and target sets\n",
    "feature_cols = list(dataset.columns[:-2])\n",
    "target_col = dataset.columns[-1]\n",
    "\n",
    "#Show the list of columns\n",
    "print \"Feature columns:\\n{}\".format(feature_cols)\n",
    "print \"\\nTarget column: {}\".format(target_col)\n",
    "\n",
    "#Separate data into feature data and target data\n",
    "X_all = dataset[feature_cols]\n",
    "y_all = dataset[target_col]\n",
    "\n",
    "#Pre-process feature dataset to create binary variables\n",
    "X_all = preprocess_features(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the model using two classifiers, (1) Naive Bayes and (2) an Ensemble of Naive Bayes learners using bagging. We first use k-fold cross validation to train the models and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 3.6522 seconds\n",
      "\n",
      "Cross-Validation scores for GaussianNB using 10 iterations:\n",
      "\n",
      "[ 0.39554232  0.40195589  0.40117247  0.40674428  0.40035989  0.40263315\n",
      "  0.40679165  0.40478973  0.4016804   0.39069539]\n",
      "F1 Score: 0.4012 (+/- 0.0094)\n",
      "\n",
      "\n",
      "\n",
      "Trained model in 20.2808 seconds\n",
      "\n",
      "Cross-Validation scores for BaggingClassifier using 10 iterations:\n",
      "\n",
      "[ 0.3950434   0.40065071  0.40261885  0.40768199  0.39939588  0.40323529\n",
      "  0.4041422   0.403398    0.39548808  0.39085309]\n",
      "F1 Score: 0.4003 (+/- 0.0097)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from time import time\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "def performance_metric(y_true, y_pred):\n",
    "    return f1_score(y_true,y_pred,average='weighted')\n",
    "\n",
    "def cross_validation(clf, X_train, y_train, fit_params=None):\n",
    "    cv_iters = 10\n",
    "    cv_sets = ShuffleSplit(X_train.shape[0], n_iter=cv_iters, test_size=0.2, random_state=0)\n",
    "    scoring_fnc = make_scorer(performance_metric)  \n",
    "\n",
    "    start = time()\n",
    "    scores = cross_val_score(clf, X_train, y=y_train, fit_params=fit_params, scoring=scoring_fnc, cv=cv_sets)\n",
    "    end = time()\n",
    "\n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "    print \"\\nCross-Validation scores for {} using {} iterations:\\n\".format(clf.__class__.__name__,cv_iters)\n",
    "    print scores\n",
    "    print(\"F1 Score: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print '\\n\\n'\n",
    "    \n",
    "clf_A = GaussianNB()\n",
    "clf_B = BaggingClassifier(clf_A, random_state=2)\n",
    "\n",
    "cross_validation(clf_A,X_all,y_all)\n",
    "cross_validation(clf_B,X_all,y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validations scores indicate the models perform a bit better than the benchmark of 0.33. Next, we look into more details of how the models perform in classifying each class, using the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for NB:\n",
      "Made predictions in 0.0304 seconds.\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       DOWN       0.43      0.37      0.40      6341\n",
      "     STABLE       0.41      0.43      0.42      6377\n",
      "         UP       0.39      0.42      0.40      6572\n",
      "\n",
      "avg / total       0.41      0.41      0.40     19290\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results for Bagging:\n",
      "Made predictions in 0.3473 seconds.\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       DOWN       0.43      0.36      0.39      6341\n",
      "     STABLE       0.40      0.43      0.42      6377\n",
      "         UP       0.39      0.43      0.41      6572\n",
      "\n",
      "avg / total       0.41      0.41      0.41     19290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    print \"Classification Report: \\n\" + str(classification_report(target,y_pred))\n",
    "\n",
    "#We arbitrarily set the number of training points to 80%\n",
    "num_train = int(X_all.shape[0]*0.8)\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = num_test, random_state = 1)\n",
    "\n",
    "clf_A.fit(X_train, y_train)\n",
    "clf_B.fit(X_train, y_train)\n",
    "\n",
    "print \"Results for NB:\"\n",
    "predict_labels(clf_A, X_test, y_test)\n",
    "print '\\n\\n'\n",
    "print \"Results for Bagging:\"\n",
    "predict_labels(clf_B, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate the models are classifying each label with roughly equal precision and recall. \n",
    "\n",
    "## Parameter Optimization\n",
    "\n",
    "We next try to tune parameters of the ensemble model using GridSearch and cross-validation. NOTE: The code below takes a long time to run, but results are copied below.\n",
    "\n",
    "***NOTE THE FOLLOWING BLOCK TAKES A LONG TIME TO RUN, BUT CAN BE SKIPPED***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THIS BLOCK WILL TAKE A LONG TIME TO RUN\n",
    "# YOU CAN SKIP AND THE REST OF THE BLOCKS WILL STILL WORK\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def train_classifierGS(clf, X_train, y_train, params=None):\n",
    "    cv_iters = 2\n",
    "    cv_sets = ShuffleSplit(X_train.shape[0], n_iter=cv_iters, test_size=0.20, random_state=0)\n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search object\n",
    "    grid = GridSearchCV(clf, params, scoring=scoring_fnc, cv=cv_sets)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print \"best_params_ for the optimal model are: {}.\".format(str(grid.best_params_))\n",
    "    return grid.best_estimator_\n",
    "\n",
    "params={'n_estimators': [1,10,100,500,1000], 'max_samples': [0.3,0.5,1.0], 'max_features': [0.3,0.5,1.0]}\n",
    "best_bagging_clf = train_classifierGS(clf_B, X_train, y_train, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the grid search indicate the following are the best parameters:\n",
    "\n",
    "best_params_ for the optimal model are: {'max_features': 0.3, 'max_samples': 0.5, 'n_estimators': 100}.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Bagging:\n",
      "Trained model in 54.7251 seconds\n",
      "\n",
      "Cross-Validation scores for BaggingClassifier using 10 iterations:\n",
      "\n",
      "[ 0.39726444  0.40226551  0.40427847  0.40923715  0.40187027  0.40537049\n",
      "  0.40609196  0.40498949  0.39806448  0.39302724]\n",
      "F1 Score: 0.4022 (+/- 0.0092)\n",
      "\n",
      "\n",
      "\n",
      "Made predictions in 0.9440 seconds.\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      above       0.40      0.44      0.42      6572\n",
      "      below       0.43      0.37      0.40      6341\n",
      "     middle       0.41      0.42      0.42      6377\n",
      "\n",
      "avg / total       0.41      0.41      0.41     19290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Results for Bagging:\"\n",
    "cross_validation(best_bagging_clf,X_all,y_all)\n",
    "predict_labels(best_bagging_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results with the optimal parameters (F1 Score: 0.4022) were only marginally better than with the default parameters (F1 Score: 0.4003)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "\n",
    "The code below performs all the preprocessing steps again using new variable, in order to preserve the Company, Month, and Return numbers for each datapoint. Then we obtain the top confidence predictions that the model yields in order to assess their performance. See the Model Evaluation and Validation Section of the report for more details on these portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0        1     2       3                 4         5\n",
      "15960   UNT  2011-06  DOWN    DOWN   -0.104260989149  0.701770\n",
      "9098   SLCA  2013-06  DOWN    DOWN   -0.458631326212  0.678251\n",
      "7754    UNT  2011-03  DOWN    DOWN   -0.160898545378  0.673817\n",
      "4312    EEQ  2013-11  DOWN    DOWN   -0.232851191059  0.642364\n",
      "616     WLL  2012-02  DOWN  STABLE   0.0100388284056  0.622348\n",
      "7797   SLCA  2012-07  DOWN      UP     1.19795096909  0.621403\n",
      "13244   NGL  2012-07  DOWN      UP    0.223497806037  0.614668\n",
      "5773   ENLC  2014-03  DOWN    DOWN   -0.734449961872  0.611460\n",
      "12004   MDR  2013-09  DOWN    DOWN   -0.283808352244  0.610698\n",
      "9609    WGP  2014-06  DOWN    DOWN   -0.320706536349  0.608916\n",
      "15691   BWP  2013-11  DOWN    DOWN   -0.254832641306  0.608861\n",
      "7689   ENBL  2014-03  DOWN    DOWN   -0.636109502496  0.606810\n",
      "12533  CVRR  2012-12  DOWN  STABLE  -0.0175873114779  0.605505\n",
      "13183   UNT  2011-08  DOWN    DOWN   -0.128695085235  0.604216\n",
      "2393    GEL  2012-08  DOWN  STABLE  -0.0726908388025  0.603567\n",
      "12079   GEL  2011-04  DOWN      UP     0.46960215203  0.601394\n",
      "1255    KOS  2011-04  DOWN    DOWN   -0.256496072168  0.600888\n",
      "9228    UNT  2011-09  DOWN  STABLE  -0.0232758003948  0.598293\n",
      "6729   TRGP  2012-01  DOWN      UP    0.278277107705  0.598212\n",
      "3482     NE  2014-05  DOWN    DOWN   -0.317108297196  0.598053\n",
      "12622   OAS  2011-07  DOWN      UP    0.324255265181  0.596712\n",
      "2856   SYRG  2014-03  DOWN    DOWN    -0.42709933678  0.596516\n",
      "4556    OII  2013-12  DOWN    DOWN   -0.307434616284  0.595902\n",
      "8315    NSH  2011-05  DOWN    DOWN   -0.154731821004  0.595661\n",
      "4177    LNG  2014-11  DOWN    DOWN   -0.212467526383  0.594792\n",
      "11487   OKE  2013-12  DOWN    DOWN   -0.417193146197  0.594154\n",
      "12696  SYRG  2013-07  DOWN    DOWN    -0.17336945489  0.592784\n",
      "13264   LPI  2011-09  DOWN  STABLE   0.0352785053055  0.592317\n",
      "4003    NSH  2012-08  DOWN      UP    0.533655044225  0.591764\n",
      "14626   RMP  2014-09  DOWN      UP    0.263845083502  0.591742\n",
      "12072   OKE  2013-02  DOWN    DOWN   -0.316300253448  0.590742\n",
      "3414    CQP  2011-08  DOWN  STABLE  0.00805599119518  0.590513\n",
      "2253    NGL  2012-08  DOWN      UP    0.385653232799  0.589244\n",
      "5549    CHK  2011-05  DOWN    DOWN   -0.124252967103  0.588894\n",
      "8324    TNH  2011-03  DOWN  STABLE  -0.0415583265817  0.588549\n",
      "4962    OKS  2011-09  DOWN    DOWN   -0.219059213011  0.588444\n",
      "8842    OKS  2012-05  DOWN  STABLE  -0.0117849301888  0.588374\n",
      "4792   SYRG  2013-10  DOWN    DOWN   -0.166474266037  0.587831\n",
      "165     HFC  2011-08  DOWN      UP    0.138432501489  0.587235\n",
      "7416    ETE  2013-10  DOWN    DOWN     -0.3043073424  0.586362\n",
      "Brier Score: 0.215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Repeat preprocessing from the start to preserve COMPANY, MONTH, and RAW RETURN numbers\n",
    "dataset2 = pd.read_csv(\"dataset_6_12_spy_alt_norm.csv\")\n",
    "dataset2 = dataset2[dataset2.RET12 != 'None']\n",
    "dataset2 = dataset2[dataset2.RET12 != 'Fail']\n",
    "dataset2.dropna(axis=0, inplace=True)\n",
    "dataset2 = dataset2.drop(['RET6'], axis=1)\n",
    "dataset2 = dataset2.drop(['RET1'], axis=1)\n",
    "dataset2.rename(index=str, columns={'RET12': 'RET'}, inplace=True)\n",
    "dataset2['MKTCAP'].replace('.*Small.', 'small', inplace=True, regex=True)\n",
    "dataset2['MKTCAP'].replace('.*Mid.', 'mid', inplace=True, regex=True)\n",
    "dataset2['MKTCAP'].replace('.*Large.', 'large', inplace=True, regex=True)\n",
    "ret_data = dataset2['RET'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "y_raw = dataset2['RET']\n",
    "\n",
    "dataset2.loc[(dataset2.RET.astype(np.float64) > ft_return) & (dataset2.RET.astype(np.float64) < st_return), 'RETURN_CAT'] = np.str('STABLE')\n",
    "dataset2.loc[(dataset2.RET.astype(np.float64) <= ft_return), 'RETURN_CAT'] = np.str('DOWN')\n",
    "dataset2.loc[(dataset2.RET.astype(np.float64) >= st_return), 'RETURN_CAT'] = np.str('UP')\n",
    "\n",
    "#Extract the feature and target columns\n",
    "feature_cols = list(dataset2.columns[:-2])\n",
    "target_col = dataset2.columns[-1]\n",
    "\n",
    "#Separate data into feature data and target data\n",
    "X_all2 = dataset2[feature_cols]\n",
    "y_all2 = dataset2[target_col]\n",
    "\n",
    "num_train2 = 80000\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test2 = X_all2.shape[0] - num_train2\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train2, X_test2, y_train2, y_test2, y_train_raw, y_test_raw = train_test_split(X_all2, y_all2, y_raw, test_size = num_test2, random_state = 1)\n",
    "X_company = X_test2['COMPANY']\n",
    "X_month = X_test2['MONTH']\n",
    "X_test2 = X_test2.drop(['MONTH'], axis=1)\n",
    "X_test2 = X_test2.drop(['COMPANY'], axis=1)\n",
    "X_train2 = X_train2.drop(['MONTH'], axis=1)\n",
    "X_train2 = X_train2.drop(['COMPANY'], axis=1)\n",
    "\n",
    "X_train2 = preprocess_features(X_train2)\n",
    "X_test2 = preprocess_features(X_test2)\n",
    "\n",
    "#Obtain li\n",
    "learner = GaussianNB()\n",
    "final_clf = BaggingClassifier(learner, max_features=0.3, max_samples=0.5, n_estimators=100,random_state=3)\n",
    "final_clf.fit(X_train2,y_train2)\n",
    "#final_clf = clf_A\n",
    "prob_pos_clf = final_clf.predict_proba(X_test2)[:,0]\n",
    "sorted_prob = zip(X_company,X_month,final_clf.predict(X_test2),y_test2,y_test_raw,prob_pos_clf)\n",
    "sorted_prob_df = pd.DataFrame(sorted_prob)\n",
    "sorted_prob_df.sort_values(5,ascending=False,inplace=True)\n",
    "print sorted_prob_df.head(40)\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "clf_score = brier_score_loss(y_test2, prob_pos_clf, pos_label='DOWN')\n",
    "print(\"Brier Score: %1.3f\" % clf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the mean return for all predictions with a probability at or above 0.60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0        1     2       3                 4         5\n",
      "7754    UNT  2011-03  DOWN    DOWN   -0.160898545378  0.673817\n",
      "1255    KOS  2011-04  DOWN    DOWN   -0.256496072168  0.600888\n",
      "12079   GEL  2011-04  DOWN      UP     0.46960215203  0.601394\n",
      "15960   UNT  2011-06  DOWN    DOWN   -0.104260989149  0.701770\n",
      "13183   UNT  2011-08  DOWN    DOWN   -0.128695085235  0.604216\n",
      "616     WLL  2012-02  DOWN  STABLE   0.0100388284056  0.622348\n",
      "7797   SLCA  2012-07  DOWN      UP     1.19795096909  0.621403\n",
      "13244   NGL  2012-07  DOWN      UP    0.223497806037  0.614668\n",
      "2393    GEL  2012-08  DOWN  STABLE  -0.0726908388025  0.603567\n",
      "12533  CVRR  2012-12  DOWN  STABLE  -0.0175873114779  0.605505\n",
      "9098   SLCA  2013-06  DOWN    DOWN   -0.458631326212  0.678251\n",
      "12004   MDR  2013-09  DOWN    DOWN   -0.283808352244  0.610698\n",
      "15691   BWP  2013-11  DOWN    DOWN   -0.254832641306  0.608861\n",
      "4312    EEQ  2013-11  DOWN    DOWN   -0.232851191059  0.642364\n",
      "5773   ENLC  2014-03  DOWN    DOWN   -0.734449961872  0.611460\n",
      "7689   ENBL  2014-03  DOWN    DOWN   -0.636109502496  0.606810\n",
      "9609    WGP  2014-06  DOWN    DOWN   -0.320706536349  0.608916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamephase/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.1035840351874"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_prob_picks = sorted_prob_df[sorted_prob_df[5]>=0.60]\n",
    "high_prob_picks.sort_values(1,ascending=True,inplace=True)\n",
    "print high_prob_picks.head(30)\n",
    "high_prob_picks[4].apply(pd.to_numeric, errors='coerce').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
